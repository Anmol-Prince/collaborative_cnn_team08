{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3af6faae",
   "metadata": {},
   "source": [
    "## Run Next Cell only to create a groundtruth csv file from the testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1c4ebfe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Script to create a CSV file with image filenames, labels, and paths from a dataset organized in class-specific folders.\n",
    "\n",
    "import os\n",
    "import csv\n",
    "from pathlib import Path\n",
    "\n",
    "# Root folder where cat/ and dog/ exist\n",
    "DATA_ROOT = Path(\"/media/veer/Data/Projects/collaborative_cnn_team08/data/Data2/test_set\")   # change this if needed\n",
    "\n",
    "# Output CSV file\n",
    "CSV_PATH = Path(\"../data/Data2/test_labels.csv\")\n",
    "\n",
    "rows = []\n",
    "\n",
    "# Loop through class folders (e.g., cat, dog)\n",
    "for class_name in [\"cats\", \"dogs\"]:\n",
    "    class_path = DATA_ROOT / class_name\n",
    "\n",
    "    # Make sure folder exists\n",
    "    if not class_path.exists():\n",
    "        print(f\"Folder not found: {class_path}\")\n",
    "        continue\n",
    "\n",
    "    # Loop through files inside class folder\n",
    "    for filename in os.listdir(class_path):\n",
    "        if filename.lower().endswith((\".jpg\", \".png\", \".jpeg\")):\n",
    "            # save filename and label and image path\n",
    "            rows.append([filename, class_name, str(class_path / filename)])\n",
    "\n",
    "# Write to CSV\n",
    "with open(CSV_PATH, 'w', newline='') as csvfile:\n",
    "    csvwriter = csv.writer(csvfile)\n",
    "    csvwriter.writerow([\"filename\", \"label\", \"image_path\"])  # header\n",
    "    csvwriter.writerows(rows)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cbcbd45",
   "metadata": {},
   "source": [
    "# Testing the prediction and ground truth with random sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b3bb1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# Cell 1: Imports & Config\n",
    "# =========================\n",
    "\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from time import time\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, classification_report\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "from models.model_v2 import CustomCNN\n",
    "from utils.metrics import compute_metrics, print_metrics, save_metrics, load_metrics\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", DEVICE)\n",
    "\n",
    "PROJECT_ROOT = Path(\"../\").resolve()\n",
    "\n",
    "CSV_PATH = PROJECT_ROOT / \"data\" / \"Data2\" / \"test_labels.csv\"\n",
    "MODEL_WEIGHTS_PATH = PROJECT_ROOT / \"models\" / \"model_v2.pth\"\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "IMAGE_SIZE = 224\n",
    "\n",
    "label_to_idx = {\n",
    "    \"cats\": 0,\n",
    "    \"dogs\": 1,\n",
    "}\n",
    "idx_to_label = {v: k for k, v in label_to_idx.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac8c9365",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples in CSV: 2023\n",
      "       filename label                                         image_path\n",
      "0  cat.4301.jpg  cats  /media/veer/Data/Projects/collaborative_cnn_te...\n",
      "1  cat.4606.jpg  cats  /media/veer/Data/Projects/collaborative_cnn_te...\n",
      "2  cat.4980.jpg  cats  /media/veer/Data/Projects/collaborative_cnn_te...\n",
      "3  cat.4981.jpg  cats  /media/veer/Data/Projects/collaborative_cnn_te...\n",
      "4  cat.4982.jpg  cats  /media/veer/Data/Projects/collaborative_cnn_te...\n",
      "After shuffling:\n",
      "       filename label                                         image_path\n",
      "0  cat.4642.jpg  cats  /media/veer/Data/Projects/collaborative_cnn_te...\n",
      "1  cat.4945.jpg  cats  /media/veer/Data/Projects/collaborative_cnn_te...\n",
      "2  cat.4690.jpg  cats  /media/veer/Data/Projects/collaborative_cnn_te...\n",
      "3  cat.4573.jpg  cats  /media/veer/Data/Projects/collaborative_cnn_te...\n",
      "4  cat.4558.jpg  cats  /media/veer/Data/Projects/collaborative_cnn_te...\n",
      "Test samples: 2023\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# Cell 2: Transform & Dataset\n",
    "# =========================\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# Load CSV\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "print(\"Total samples in CSV:\", len(df))\n",
    "print(df.head())\n",
    "\n",
    "# Shuffle rows\n",
    "df = df.sample(frac=1.0, random_state=42).reset_index(drop=True)\n",
    "print(\"After shuffling:\")\n",
    "print(df.head())\n",
    "\n",
    "\n",
    "class CSVDataset(Dataset):\n",
    "    def __init__(self, dataframe, transform=None, label_to_idx=None):\n",
    "        self.df = dataframe\n",
    "        self.transform = transform\n",
    "        self.label_to_idx = label_to_idx\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        img_path = row[\"image_path\"]\n",
    "        label_str = row[\"label\"]\n",
    "\n",
    "        # convert label string to index\n",
    "        if self.label_to_idx is not None:\n",
    "            label = self.label_to_idx[label_str]\n",
    "        else:\n",
    "            label = int(label_str)\n",
    "\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label, img_path\n",
    "\n",
    "\n",
    "test_dataset = CSVDataset(df, transform=val_transform, label_to_idx=label_to_idx)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "print(\"Test samples:\", len(test_dataset))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "aabbedec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "# Load model\n",
    "model = CustomCNN(num_classes=2).to(DEVICE)\n",
    "model.load_state_dict(torch.load(MODEL_WEIGHTS_PATH, map_location=DEVICE))\n",
    "model.eval()\n",
    "\n",
    "print(\"Model loaded successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7745abb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded weights from /media/veer/Data/Projects/collaborative_cnn_team08/models/model_v2.pth\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CustomCNN(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (4): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (6): ReLU(inplace=True)\n",
       "    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (8): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (9): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (10): ReLU(inplace=True)\n",
       "    (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (global_pool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (classifier): Sequential(\n",
       "    (0): Flatten(start_dim=1, end_dim=-1)\n",
       "    (1): Linear(in_features=128, out_features=256, bias=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Dropout(p=0.5, inplace=False)\n",
       "    (4): Linear(in_features=256, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# =========================\n",
    "# Cell 3: Load Model & Weights\n",
    "# =========================\n",
    "\n",
    "num_classes = len(label_to_idx)\n",
    "\n",
    "model = CustomCNN(num_classes=num_classes).to(DEVICE)\n",
    "\n",
    "if MODEL_WEIGHTS_PATH.exists():\n",
    "    state_dict = torch.load(MODEL_WEIGHTS_PATH, map_location=DEVICE)\n",
    "    model.load_state_dict(state_dict)\n",
    "    print(f\"Loaded weights from {MODEL_WEIGHTS_PATH}\")\n",
    "else:\n",
    "    raise FileNotFoundError(f\"Model weights not found at {MODEL_WEIGHTS_PATH}\")\n",
    "\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6ab8ffb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference completed in 9.50 seconds.\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# Cell 4: Inference on Test CSV\n",
    "# =========================\n",
    "\n",
    "all_labels = []\n",
    "all_preds = []\n",
    "all_paths = []\n",
    "\n",
    "start_time = time()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels, paths in test_loader:\n",
    "        images = images.to(DEVICE)\n",
    "        labels = labels.to(DEVICE)\n",
    "\n",
    "        outputs = model(images)\n",
    "        preds = torch.argmax(outputs, dim=1)\n",
    "\n",
    "        all_labels.extend(labels.cpu().tolist())\n",
    "        all_preds.extend(preds.cpu().tolist())\n",
    "        all_paths.extend(paths)\n",
    "\n",
    "total_time = time() - start_time\n",
    "print(f\"Inference completed in {total_time:.2f} seconds.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9fe06660",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.8552\n",
      "Test F1 (macro): 0.8549\n",
      "Confusion Matrix (rows=true, cols=pred):\n",
      "[[825 186]\n",
      " [107 905]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        cats       0.89      0.82      0.85      1011\n",
      "        dogs       0.83      0.89      0.86      1012\n",
      "\n",
      "    accuracy                           0.86      2023\n",
      "   macro avg       0.86      0.86      0.85      2023\n",
      "weighted avg       0.86      0.86      0.85      2023\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# Cell 5: Metrics & Report\n",
    "# =========================\n",
    "\n",
    "acc = accuracy_score(all_labels, all_preds)\n",
    "f1 = f1_score(all_labels, all_preds, average=\"macro\")\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "\n",
    "print(f\"Test Accuracy: {acc:.4f}\")\n",
    "print(f\"Test F1 (macro): {f1:.4f}\")\n",
    "print(\"Confusion Matrix (rows=true, cols=pred):\")\n",
    "print(cm)\n",
    "\n",
    "target_names = [idx_to_label[i] for i in range(len(idx_to_label))]\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(all_labels, all_preds, target_names=target_names))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ff115d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to /media/veer/Data/Projects/collaborative_cnn_team08/results/test_results_v2.json\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# Cell 6: Save results in json with accuracy, f1 score, confusion matrix\n",
    "# =========================\n",
    "\n",
    "import json\n",
    "results = {\n",
    "    \"accuracy\": acc,\n",
    "    \"f1_macro\": f1,\n",
    "    \"confusion_matrix\": cm.tolist(),\n",
    "    \"classification_report\": classification_report(all_labels, all_preds, target_names=target_names, output_dict=True),\n",
    "    \"number_of_samples\": len(all_labels),\n",
    "}\n",
    "\n",
    "RESULTS_PATH = PROJECT_ROOT / \"results\" / \"test_results_v2.json\"\n",
    "with open(RESULTS_PATH, 'w') as f:\n",
    "    json.dump(results, f, indent=4)\n",
    "print(f\"Results saved to {RESULTS_PATH}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecfa6a40",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env (3.10.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
