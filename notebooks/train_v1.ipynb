{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "596f0914",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATA_DIR = F:\\Projects\\collaborative_cnn_team08\\data\n",
      "Train folder = F:\\Projects\\collaborative_cnn_team08\\data\\training_set\n",
      "Val folder   = F:\\Projects\\collaborative_cnn_team08\\data\\test_set\n"
     ]
    }
   ],
   "source": [
    "# Config\n",
    "DATA_DIR = 'F:\\Projects\\collaborative_cnn_team08\\data'              # root data folder containing training_set/ and test_set/\n",
    "OUTPUT_DIR = 'results'\n",
    "MODEL_SAVE_PATH = 'models/model_v1.pth'\n",
    "FINAL_METRICS_PATH = f\"{OUTPUT_DIR}/metrics_v1.json\"\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 15\n",
    "LR = 1e-3\n",
    "NUM_WORKERS = 4\n",
    "IMAGE_SIZE = (224, 224)\n",
    "\n",
    "import os\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "os.makedirs(os.path.dirname(MODEL_SAVE_PATH), exist_ok=True)\n",
    "print('DATA_DIR =', DATA_DIR)\n",
    "print('Train folder =', os.path.join(DATA_DIR, 'training_set'))\n",
    "print('Val folder   =', os.path.join(DATA_DIR, 'test_set'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fd43b9a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import time\n",
    "import random\n",
    "import os, sys\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "from pathlib import Path\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    f1_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    confusion_matrix,\n",
    ")\n",
    "\n",
    "import json\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms, datasets\n",
    "\n",
    "# Project code (ensure you're running notebook from repo root)\n",
    "from models.model_v1 import get_model\n",
    "# from utils.metrics import compute_classification_metrics, save_metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "928bfc3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "\n",
    "  # Helper functions (corrected)\n",
    "import os\n",
    "import json        # <-- REQUIRED\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "\n",
    "def safe_num_workers(requested):\n",
    "    if os.name == 'nt':\n",
    "        return 0\n",
    "    try:\n",
    "        import multiprocessing\n",
    "        cpus = multiprocessing.cpu_count()\n",
    "        return min(max(0, requested), max(1, cpus - 1))\n",
    "    except Exception:\n",
    "        return 0\n",
    "\n",
    "\n",
    "def save_metrics(metrics: dict, path: str):\n",
    "    \"\"\"Save metrics dict as JSON.\"\"\"\n",
    "    os.makedirs(os.path.dirname(path), exist_ok=True)\n",
    "    with open(path, \"w\") as f:\n",
    "        json.dump(metrics, f, indent=2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a37608bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes: ['cats', 'dogs']\n",
      "Train samples: 8005 Val samples: 2023\n",
      "num_workers = 0\n"
     ]
    }
   ],
   "source": [
    "# Prepare datasets and dataloaders\n",
    "train_dir = os.path.join(DATA_DIR, 'training_set')\n",
    "val_dir = os.path.join(DATA_DIR, 'test_set')\n",
    "\n",
    "if not (os.path.isdir(train_dir) and os.path.isdir(val_dir)):\n",
    "    raise RuntimeError(f\"Expected folders not found. Ensure '{train_dir}' and '{val_dir}' exist.\")\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize(IMAGE_SIZE),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize(IMAGE_SIZE),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "train_ds = datasets.ImageFolder(train_dir, transform=train_transform)\n",
    "val_ds = datasets.ImageFolder(val_dir, transform=val_transform)\n",
    "\n",
    "num_workers = safe_num_workers(NUM_WORKERS)\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, num_workers=num_workers)\n",
    "val_loader = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=num_workers)\n",
    "\n",
    "print('Classes:', train_ds.classes)\n",
    "print('Train samples:', len(train_ds), 'Val samples:', len(val_ds))\n",
    "print('num_workers =', num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c32b4349",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n"
     ]
    }
   ],
   "source": [
    "# Model, criterion, optimizer, device\n",
    "set_seed(42)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Device:', device)\n",
    "\n",
    "num_classes = len(train_ds.classes)\n",
    "model = get_model(num_classes=num_classes, device=device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=LR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7c9a8707",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_classification_metrics(y_true, y_pred, average=\"macro\"):\n",
    "    \"\"\"\n",
    "    Compute common classification metrics for classification tasks.\n",
    "\n",
    "    Args:\n",
    "        y_true (list or np.array): Ground truth labels\n",
    "        y_pred (list or np.array): Predicted labels\n",
    "        average (str): Averaging mode for multi-class classification.\n",
    "                       Options: \"macro\", \"micro\", \"weighted\"\n",
    "\n",
    "    Returns:\n",
    "        dict: Accuracy, F1, Precision, Recall, Confusion matrix\n",
    "    \"\"\"\n",
    "    y_true = np.array(y_true)\n",
    "    y_pred = np.array(y_pred)\n",
    "\n",
    "    metrics = {\n",
    "        \"accuracy\": float(accuracy_score(y_true, y_pred)),\n",
    "        \"f1\": float(f1_score(y_true, y_pred, average=average, zero_division=0)),\n",
    "        \"precision\": float(precision_score(y_true, y_pred, average=average, zero_division=0)),\n",
    "        \"recall\": float(recall_score(y_true, y_pred, average=average, zero_division=0)),\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        cm = confusion_matrix(y_true, y_pred).tolist()\n",
    "    except Exception:\n",
    "        cm = None\n",
    "\n",
    "    metrics[\"confusion_matrix\"] = cm\n",
    "\n",
    "    return metrics\n",
    "\n",
    "\n",
    "def save_metrics(metrics: dict, path: str):\n",
    "    \"\"\"\n",
    "    Save a dictionary of metrics to a JSON file.\n",
    "\n",
    "    Args:\n",
    "        metrics (dict): metrics dictionary\n",
    "        path (str): output JSON file path\n",
    "    \"\"\"\n",
    "    with open(path, \"w\") as f:\n",
    "        json.dump(metrics, f, indent=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f15896b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training & evaluation helper functions\n",
    "def train_one_epoch(model, dataloader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    trues, preds = [], []\n",
    "    for imgs, labels in tqdm(dataloader, desc='Train', leave=False):\n",
    "        imgs = imgs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outs = model(imgs)\n",
    "        loss = criterion(outs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += float(loss.item()) * imgs.size(0)\n",
    "        preds.extend(torch.argmax(outs, dim=1).cpu().tolist())\n",
    "        trues.extend(labels.cpu().tolist())\n",
    "    avg_loss = running_loss / max(1, len(dataloader.dataset))\n",
    "    metrics = compute_classification_metrics(trues, preds)\n",
    "    metrics['loss'] = float(avg_loss)\n",
    "    return metrics\n",
    "\n",
    "\n",
    "def evaluate(model, dataloader, criterion, device):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    trues, preds = [], []\n",
    "    with torch.no_grad():\n",
    "        for imgs, labels in tqdm(dataloader, desc='Val', leave=False):\n",
    "            imgs = imgs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outs = model(imgs)\n",
    "            loss = criterion(outs, labels)\n",
    "            running_loss += float(loss.item()) * imgs.size(0)\n",
    "            preds.extend(torch.argmax(outs, dim=1).cpu().tolist())\n",
    "            trues.extend(labels.cpu().tolist())\n",
    "    avg_loss = running_loss / max(1, len(dataloader.dataset))\n",
    "    metrics = compute_classification_metrics(trues, preds)\n",
    "    metrics['loss'] = float(avg_loss)\n",
    "    return metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "81a69e75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Epoch 1/15 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: {'accuracy': 0.5982510930668332, 'f1': 0.5956584558447966, 'precision': 0.6009096615552283, 'recall': 0.5983013420724095, 'confusion_matrix': [[2715, 1285], [1931, 2074]], 'loss': 0.6574149778900409}\n",
      "Val:   {'accuracy': 0.6198714780029659, 'f1': 0.5955591466868824, 'precision': 0.6580805284437692, 'recall': 0.6199928259501218, 'confusion_matrix': [[875, 136], [633, 379]], 'loss': 0.6401151240431785}\n",
      "Saved best model to models/model_v1.pth\n",
      "\n",
      "=== Epoch 2/15 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: {'accuracy': 0.618738288569644, 'f1': 0.6166345114458903, 'precision': 0.6214737064251081, 'recall': 0.6187848002496878, 'confusion_matrix': [[2773, 1227], [1825, 2180]], 'loss': 0.6411505076976064}\n",
      "Val:   {'accuracy': 0.6238260009886307, 'f1': 0.6153674339398916, 'precision': 0.6356451246582504, 'recall': 0.6237528490947405, 'confusion_matrix': [[481, 530], [231, 781]], 'loss': 0.6298901717290393}\n",
      "Saved best model to models/model_v1.pth\n",
      "\n",
      "=== Epoch 3/15 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: {'accuracy': 0.6369768894440975, 'f1': 0.6346488543796471, 'precision': 0.6406396995377642, 'recall': 0.6370269975031211, 'confusion_matrix': [[2869, 1131], [1775, 2230]], 'loss': 0.6252156940867646}\n",
      "Val:   {'accuracy': 0.5684626791893228, 'f1': 0.5259221220988524, 'precision': 0.6064657838056853, 'recall': 0.5683147433566734, 'confusion_matrix': [[272, 739], [134, 878]], 'loss': 0.7708852880082387}\n",
      "\n",
      "=== Epoch 4/15 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: {'accuracy': 0.6498438475952529, 'f1': 0.647730672240048, 'precision': 0.6536080281464898, 'recall': 0.6498924781523097, 'confusion_matrix': [[2911, 1089], [1714, 2291]], 'loss': 0.6205748750707792}\n",
      "Val:   {'accuracy': 0.6080079090459714, 'f1': 0.5772102298827249, 'precision': 0.652116566192827, 'recall': 0.6078746437409837, 'confusion_matrix': [[342, 669], [124, 888]], 'loss': 0.6988726464816973}\n",
      "\n",
      "=== Epoch 5/15 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: {'accuracy': 0.6699562773266708, 'f1': 0.6689515549871501, 'precision': 0.6721039600174781, 'recall': 0.6699909488139826, 'confusion_matrix': [[2902, 1098], [1544, 2461]], 'loss': 0.6010734220804981}\n",
      "Val:   {'accuracy': 0.7024221453287197, 'f1': 0.7019203845664327, 'precision': 0.7038315816406866, 'recall': 0.7024425978270643, 'confusion_matrix': [[752, 259], [343, 669]], 'loss': 0.5711784782353098}\n",
      "Saved best model to models/model_v1.pth\n",
      "\n",
      "=== Epoch 6/15 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: {'accuracy': 0.683947532792005, 'f1': 0.6829049942958549, 'precision': 0.6864625181817906, 'recall': 0.6839836142322098, 'confusion_matrix': [[2967, 1033], [1497, 2508]], 'loss': 0.5897110028910235}\n",
      "Val:   {'accuracy': 0.6979733069698467, 'f1': 0.6965612982495333, 'precision': 0.7017904278101499, 'recall': 0.698007197507262, 'confusion_matrix': [[775, 236], [375, 637]], 'loss': 0.570603190438322}\n",
      "\n",
      "=== Epoch 7/15 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: {'accuracy': 0.6935665209244223, 'f1': 0.6927917696840478, 'precision': 0.6955957996986198, 'recall': 0.6935981585518103, 'confusion_matrix': [[2977, 1023], [1430, 2575]], 'loss': 0.581405112841664}\n",
      "Val:   {'accuracy': 0.7296094908551656, 'f1': 0.7290732682585497, 'precision': 0.7314846562660724, 'recall': 0.7296316604309121, 'confusion_matrix': [[783, 228], [319, 693]], 'loss': 0.552115708869457}\n",
      "Saved best model to models/model_v1.pth\n",
      "\n",
      "=== Epoch 8/15 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: {'accuracy': 0.7001873828856965, 'f1': 0.6992580069503147, 'precision': 0.7027568387616745, 'recall': 0.7002223782771535, 'confusion_matrix': [[3025, 975], [1425, 2580]], 'loss': 0.574425446294681}\n",
      "Val:   {'accuracy': 0.7192288680177954, 'f1': 0.7114093690037271, 'precision': 0.7460588215942363, 'recall': 0.7193104115597988, 'confusion_matrix': [[894, 117], [451, 561]], 'loss': 0.5533670250342968}\n",
      "\n",
      "=== Epoch 9/15 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: {'accuracy': 0.7051842598376015, 'f1': 0.7043350956141469, 'precision': 0.707631117809013, 'recall': 0.7052180087390761, 'confusion_matrix': [[3037, 963], [1397, 2608]], 'loss': 0.5656454166645262}\n",
      "Val:   {'accuracy': 0.7103311913000494, 'f1': 0.7012343998870945, 'precision': 0.7396929311822928, 'recall': 0.7104176196228835, 'confusion_matrix': [[895, 116], [470, 542]], 'loss': 0.5622376466645973}\n",
      "\n",
      "=== Epoch 10/15 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: {'accuracy': 0.714053716427233, 'f1': 0.7132568320577304, 'precision': 0.7165223803877396, 'recall': 0.7140869225967541, 'confusion_matrix': [[3069, 931], [1358, 2647]], 'loss': 0.5563982343018464}\n",
      "Val:   {'accuracy': 0.7009391992090954, 'f1': 0.6893954947545051, 'precision': 0.7362452075594791, 'recall': 0.7010346661036895, 'confusion_matrix': [[904, 107], [498, 514]], 'loss': 0.5912070703046839}\n",
      "\n",
      "=== Epoch 11/15 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: {'accuracy': 0.7175515302935666, 'f1': 0.7167417869687799, 'precision': 0.7201317538799026, 'recall': 0.7175852059925094, 'confusion_matrix': [[3086, 914], [1347, 2658]], 'loss': 0.5506629934391329}\n",
      "Val:   {'accuracy': 0.7132970835392981, 'f1': 0.7061731338260248, 'precision': 0.7363706052022971, 'recall': 0.7133742273724212, 'confusion_matrix': [[879, 132], [448, 564]], 'loss': 0.5548876668931939}\n",
      "\n",
      "=== Epoch 12/15 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: {'accuracy': 0.7271705184259838, 'f1': 0.7265180499851518, 'precision': 0.7294186810801326, 'recall': 0.7272013108614233, 'confusion_matrix': [[3106, 894], [1290, 2715]], 'loss': 0.5465765488512586}\n",
      "Val:   {'accuracy': 0.7474048442906575, 'f1': 0.7466558050636343, 'precision': 0.7504204083005415, 'recall': 0.7474319051696164, 'confusion_matrix': [[811, 200], [311, 701]], 'loss': 0.509429448468816}\n",
      "Saved best model to models/model_v1.pth\n",
      "\n",
      "=== Epoch 13/15 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: {'accuracy': 0.7297938788257339, 'f1': 0.729062177866705, 'precision': 0.7323669360620577, 'recall': 0.7298266229712859, 'confusion_matrix': [[3129, 871], [1292, 2713]], 'loss': 0.534618564168786}\n",
      "Val:   {'accuracy': 0.7004448838358873, 'f1': 0.693193967277707, 'precision': 0.7212141289405021, 'recall': 0.7003690628384216, 'confusion_matrix': [[553, 458], [148, 864]], 'loss': 0.5741409480689601}\n",
      "\n",
      "=== Epoch 14/15 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: {'accuracy': 0.7390381011867583, 'f1': 0.7386098914906654, 'precision': 0.7406650393592722, 'recall': 0.7390636704119851, 'confusion_matrix': [[3120, 880], [1209, 2796]], 'loss': 0.5348125541232512}\n",
      "Val:   {'accuracy': 0.6608996539792388, 'f1': 0.6431647402708267, 'precision': 0.7010722829801777, 'recall': 0.6610100163028818, 'confusion_matrix': [[894, 117], [569, 443]], 'loss': 0.6274031296674415}\n",
      "\n",
      "=== Epoch 15/15 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: {'accuracy': 0.7379138038725797, 'f1': 0.737414691189674, 'precision': 0.7397905847429873, 'recall': 0.7379413233458177, 'confusion_matrix': [[3128, 872], [1226, 2779]], 'loss': 0.5281990752824763}\n",
      "Val:   {'accuracy': 0.7118141374196737, 'f1': 0.7009257942053484, 'precision': 0.7481379113018598, 'recall': 0.7119086295805428, 'confusion_matrix': [[913, 98], [485, 527]], 'loss': 0.5575503963559085}\n",
      "\n",
      "Training finished. Total time: 2056.5s\n",
      "Final metrics saved to results/metrics_v1.json\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "best_val_f1 = -1.0\n",
    "history = {'epochs': []}\n",
    "start_time = time.time()\n",
    "\n",
    "for epoch in range(1, EPOCHS+1):\n",
    "    t0 = time.time()\n",
    "    print(f\"\\n=== Epoch {epoch}/{EPOCHS} ===\")\n",
    "    train_metrics = train_one_epoch(model, train_loader, criterion, optimizer, device)\n",
    "    val_metrics = evaluate(model, val_loader, criterion, device)\n",
    "    epoch_time = time.time() - t0\n",
    "    print('Train:', train_metrics)\n",
    "    print('Val:  ', val_metrics)\n",
    "\n",
    "    rec = {'epoch': epoch, 'train': train_metrics, 'val': val_metrics, 'time_s': epoch_time}\n",
    "    history['epochs'].append(rec)\n",
    "    save_metrics(rec, os.path.join(OUTPUT_DIR, f'metrics_v1_epoch{epoch}.json'))\n",
    "\n",
    "    val_f1 = float(val_metrics.get('f1', 0.0))\n",
    "    if val_f1 > best_val_f1:\n",
    "        best_val_f1 = val_f1\n",
    "        torch.save(model.state_dict(), MODEL_SAVE_PATH)\n",
    "        print('Saved best model to', MODEL_SAVE_PATH)\n",
    "\n",
    "total_time = time.time() - start_time\n",
    "history['summary'] = {'total_time_s': total_time, 'best_val_f1': best_val_f1}\n",
    "save_metrics(history, FINAL_METRICS_PATH)\n",
    "print('\\nTraining finished. Total time: {:.1f}s'.format(total_time))\n",
    "print('Final metrics saved to', FINAL_METRICS_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "344c208c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
